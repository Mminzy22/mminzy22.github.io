---
title: "LLM 활용 기법: 프롬프트 트렁케이션, CoT, RAG 개념 정리"
author: mminzy22
date: 2025-01-31 12:00:00 +0900
categories: [Machine Learning, Deep Learning, LLM]
tags: [Bootcamp, Python, Machine Learning, Deep Learning, LLM, CoT, RAG, TIL]
description: "프롬프트 트렁케이션, Chain-of-Thought(CoT), Retrieval-Augmented Generation(RAG) 개념 정리"
pin: false
---


## 1. 프롬프트 트렁케이션과 컨텍스트 손실 현상

### (1) 프롬프트 트렁케이션이란?
프롬프 트 트렁케이션(Prompt Truncation)은 대형 언어 모델(LLM)에서 입력 길이 제한을 초과하는 경우, 모델이 일부 입력을 잘라내는 현상을 의미합니다. 이는 **모델이 중요한 컨텍스트를 잃어버리는 문제**를 초래할 수 있습니다.

### (2) 컨텍스트 손실(Context Loss)과 영향
프롬프트 트렁케이션이 발생하면 다음과 같은 문제가 발생할 수 있습니다:
- **문맥 부족**: 중요한 정보가 삭제되어 모델이 질문에 대한 완전한 답변을 제공하지 못함.
- **일관성 문제**: 모델이 이전 내용을 기억하지 못하고 비논리적인 응답을 생성할 가능성이 증가.
- **추론 성능 저하**: 논리적인 연결이 끊어져 부정확한 결과를 출력할 가능성 증가.

### (3) 해결 방법
1. **입력 최적화**: 불필요한 정보를 제거하여 중요한 컨텍스트를 유지.
2. **프롬프트 체이닝**: 여러 개의 프롬프트를 연결하여 점진적으로 정보를 주입.
3. **요약 활용**: 긴 문서를 압축하여 핵심 내용만 전달.
4. **RAG 활용**: Retrieval-Augmented Generation을 사용하여 필요한 정보를 검색 후 답변 생성.


## 2. CoT (Chain-of-Thought) 방식

### (1) CoT란?
**Chain-of-Thought(CoT)**는 복잡한 문제 해결을 위해 **논리적인 사고 과정을 명시적으로 모델이 따르게 하는 기법**입니다. 모델이 답을 단순히 예측하는 것이 아니라, **중간 사고 과정**을 먼저 생각한 후 최종 답변을 생성하도록 유도합니다.

### (2) CoT의 원리
기존 모델이 "2 + 3 * 4 = ?" 같은 문제를 해결할 때 **직접 답을 생성하는 방식**이었다면, CoT를 사용하면 다음과 같이 단계적으로 사고합니다:

**기존 방식:**

```
입력: 2 + 3 * 4 = ?
출력: 14
```

**CoT 방식:**

```
입력: 2 + 3 * 4 = ?
출력:
1. 먼저 3과 4를 곱한다. 3 * 4 = 12
2. 이후 2를 더한다. 2 + 12 = 14
3. 따라서 정답은 14이다.
```

### (3) CoT의 장점
- **복잡한 논리 문제 해결 가능**: 단계별 사고 과정이 명시되므로 계산 문제, 논리 퍼즐 등에 강함.
- **설명 가능성 향상**: 모델이 어떻게 답을 도출했는지 이해 가능.
- **추론 성능 개선**: 특히, 수학 문제 및 논리적 질문에 대한 정확도가 높아짐.

### (4) CoT 활용 사례
- **수학 문제 해결**: 모델이 논리적으로 수식을 풀도록 유도.
- **법률 문서 분석**: 논리적 근거를 단계적으로 제시하며 설명.
- **코딩 문제 해결**: 코드 작성 과정을 단계적으로 설명하며 디버깅 가능.


## 3. RAG (Retrieval-Augmented Generation)

### (1) RAG란?
**Retrieval-Augmented Generation(RAG)**는 **외부 데이터베이스에서 관련 정보를 검색(Retrieval)한 후, 이를 활용해 텍스트를 생성(Generation)하는 기법**입니다.

### (2) RAG의 원리
1. **질문 입력** → 사용자 입력을 분석.
2. **정보 검색** → 외부 문서, 데이터베이스, 벡터 DB 등에서 관련 정보를 검색.
3. **텍스트 생성** → 검색된 정보를 바탕으로 답변 생성.

### (3) RAG의 장점
- **최신 정보 반영**: 모델이 학습하지 않은 최신 데이터를 검색해 활용 가능.
- **컨텍스트 보강**: 모델이 제한된 컨텍스트 윈도우 내에서 정보를 유지하는 한계를 극복.
- **정확도 향상**: 검색된 정보를 활용하여 더 신뢰도 높은 응답 제공.

### (4) RAG 활용 사례
- **질문 응답 시스템(QA)**: 논문 검색, 고객 서비스 챗봇 등에서 활용.
- **의료 분야**: 최신 의학 논문을 검색하여 진료 보조.
- **법률 자문**: 법률 문서를 검색하여 적절한 법 조항 추천.


## 4. 결론

- **프롬프트 트렁케이션과 컨텍스트 손실**은 LLM 사용 시 주의해야 할 주요 문제로, 이를 방지하려면 입력을 최적화하거나, 요약 및 RAG 기법을 활용해야 합니다.
- **Chain-of-Thought(CoT)** 방식은 모델이 단계적으로 사고하도록 유도하여 **논리적 추론 능력을 향상**시킵니다.
- **Retrieval-Augmented Generation(RAG)** 기법은 모델이 **외부 정보를 검색하여 최신 정보를 반영**할 수 있도록 도와줍니다.
