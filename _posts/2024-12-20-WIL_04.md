---
title: "비지도 학습부터 딥러닝까지"
author: mminzy22
date: 2024-12-20 11:00:00 +0900
categories: [Bootcamp, WIL]
tags: [Bootcamp, WIL]
description: "비지도 학습, 차원 축소, 딥러닝 기초 및 심층 신경망 구현에 대한 기록"
pin: false
---



#### FACTS (사실, 객관)
이번 주는 머신러닝과 딥러닝을 중심으로 학습을 진행하며 비지도 학습, 차원 축소, 그리고 심층 신경망 구현까지 다양한 주제를 다루었습니다. 주요 학습 내용은 다음과 같습니다:

1. **비지도 학습**:
   - 흑백 과일 사진 데이터를 활용한 군집화.
   - k-평균 알고리즘을 통한 자동 군집화와 엘보우 방법의 활용.

2. **차원 축소와 PCA**:
   - 주성분 분석(PCA)을 사용하여 데이터 차원을 줄이고 시각화.
   - 축소된 차원으로 지도 학습 수행 및 성능 비교.

3. **딥러닝 기초**:
   - 텐서플로와 케라스를 사용해 패션 MNIST 데이터를 분류.
   - 로지스틱 회귀에서 시작해 인공 신경망 및 심층 신경망 모델로 확장.
   - 활성화 함수와 옵티마이저의 역할 이해.

4. **심층 신경망 구현**:
   - ReLU와 Adam 옵티마이저를 사용한 모델 성능 향상.


#### FEELINGS (느낌, 주관)
이번 주 학습은 복잡하고 새로운 개념들이 많아 집중력을 많이 필요로 했습니다. 특히 PCA와 딥러닝 관련 내용은 처음 접하는 부분이 많아 어려움을 느꼈지만, 점진적으로 개념이 명확해졌습니다. 심층 신경망을 직접 구현하며 성능 향상을 확인했을 때 성취감을 느꼈습니다. 반면, 비지도 학습에서는 결과를 해석하는 데 시간이 걸리며 약간의 답답함도 있었습니다.


#### FINDINGS (배운 것)
1. **비지도 학습**:
   - 데이터에서 숨겨진 패턴을 발견하는 데 매우 유용하며, 실생활 데이터에서 레이블이 없는 경우에 강력한 도구임.
   - 엘보우 방법을 사용하면 클러스터 개수를 효율적으로 선택할 수 있음.

2. **PCA**:
   - 차원 축소를 통해 데이터 크기를 줄이면서도 중요한 정보를 유지할 수 있음.
   - 시각화를 통해 데이터의 구조를 직관적으로 파악 가능.

3. **딥러닝**:
   - 층의 깊이, 활성화 함수, 옵티마이저의 선택이 모델 성능에 큰 영향을 미침.
   - ReLU와 Adam은 일반적으로 더 좋은 성능과 빠른 수렴을 제공.

4. **학습 태도**:
   - 실습과 이론을 병행하면 복잡한 개념도 더 쉽게 이해 가능.
   - 결과를 비교하고 분석하는 과정에서 많은 것을 배울 수 있음.


#### FUTURE (미래)
다음 주에는 이번 학습 내용을 더 익히고, 조금 더 자신감을 가지기 위해 다음과 같은 목표를 세웠습니다:

1. **군집화와 PCA 복습**:
   - 다시 한 번 군집화와 PCA를 복습하며, 중요한 개념들을 내 것으로 만들기.
   - 다른 예제를 찾아보고 비슷한 방식으로 실습하기.

2. **딥러닝 모델 확장**:
   - 심층 신경망에서 배운 내용을 바탕으로 조금 더 복잡한 모델을 만들어 보기.
   - 학습 시간이나 정확도에 변화를 주면서 결과를 분석해 보기.

3. **꾸준한 기록**:
   - 이번 주 배운 내용을 간단히 정리해 블로그에 공유하며 복습.
   - 하루하루 배운 내용을 기록하며 성장 과정을 눈에 보이게 만들기.


이번 주 학습을 통해 머신러닝과 딥러닝의 기본과 활용 가능성을 확인하며, 다음 주를 위한 새로운 동기와 방향을 찾을 수 있었습니다. 앞으로도 꾸준히 탐구하며 이론과 실습을 균형 있게 진행하겠습니다.