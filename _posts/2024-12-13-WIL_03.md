---
title: "머신러닝의 기본과 응용. 이번 주 학습 주요 내용 정리"
author: mminzy22
date: 2024-12-13 11:00:00 +0900
categories: [Bootcamp, WIL]
tags: [Bootcamp, WIL]
description: "머신러닝의 다양한 기법과 모델 학습"
pin: false
---


#### 이번 주 학습 목표
이번 주에는 머신러닝의 다양한 기법과 모델을 학습하며, 이를 실제 데이터에 적용하는 과정을 익혔습니다. 특히, 지도 학습, K-최근접 이웃(KNN), 선형 회귀, 규제 기법, 트리 앙상블, 교차 검증 및 그리드 서치 등 다양한 주제를 다루며, 각 기법의 특징과 장단점을 탐구했습니다. 이 글에서는 이번 주 학습의 주요 내용을 정리하고, 느낀 점과 앞으로의 계획을 공유하고자 합니다.


### 1. **FACTS (사실, 객관)**
이번 주 학습한 내용은 다음과 같습니다:

#### 1.1 지도 학습과 비지도 학습
- **지도 학습(Supervised Learning)**: 정답(타깃)이 주어진 데이터를 학습하여 새로운 데이터의 정답을 예측.
- **비지도 학습(Unsupervised Learning)**: 타깃이 없는 데이터에서 패턴을 찾아내는 방식.
- 실습: 도미와 빙어 데이터를 사용해 K-최근접 이웃 알고리즘으로 분류 및 회귀를 수행【19†source】【20†source】.

#### 1.2 K-최근접 이웃(KNN) 알고리즘
- 분류(Classification)와 회귀(Regression) 모두에 활용 가능한 간단하면서도 강력한 알고리즘.
- 모델의 복잡도를 조정하는 \\(k\\) 값을 선택하며, 거리 기반 모델의 특징을 이해.
- 실습: 물고기의 길이와 무게 데이터를 활용하여 KNN 분류 및 회귀 모델을 구현【20†source】【21†source】.

#### 1.3 선형 회귀와 다항 회귀
- **선형 회귀(Linear Regression)**: 직선 방정식을 사용하여 데이터를 설명.
- **다항 회귀(Polynomial Regression)**: 다항식 특성을 추가하여 복잡한 관계를 학습.
- 실습: 농어 데이터로 모델을 학습시키며, 다항 특성이 모델의 성능을 어떻게 향상시키는지 분석【22†source】.

#### 1.4 특성 공학과 규제
- **특성 공학(Polynomial Features)**: 데이터의 비선형 관계를 학습할 수 있도록 확장.
- **릿지(Ridge)와 라쏘(Lasso)**: 모델의 복잡도를 조정하여 과대적합을 방지.
- 실습: 물고기 데이터를 사용해 규제 기법을 적용한 다중 회귀 모델 학습【23†source】.

#### 1.5 교차 검증과 그리드 서치
- **교차 검증(Cross Validation)**: 데이터를 여러 번 나눠 모델을 평가.
- **그리드 서치(Grid Search)**: 하이퍼파라미터 튜닝을 위한 자동화 기법.
- 실습: 와인 데이터를 사용해 교차 검증 점수와 최적의 하이퍼파라미터 조합을 탐색【27†source】.

#### 1.6 트리 앙상블(Tree Ensemble)
- 랜덤 포레스트(Random Forest), 엑스트라 트리(Extra Trees), 그래디언트 부스팅(Gradient Boosting) 등의 기법을 학습.
- 실습: 와인 데이터를 활용해 앙상블 모델의 강력한 성능 확인【28†source】.


### 2. **FEELINGS (느낌, 주관)**
이번 주 학습에서 트리 앙상블과 특성 공학이 가장 인상 깊었습니다. 특히, 랜덤 포레스트와 그래디언트 부스팅의 특성 중요도를 시각적으로 확인하며, 데이터의 각 특성이 모델에 어떤 기여를 하는지 이해할 수 있었습니다. 반면, 특성 공학과 규제 기법은 복잡하게 느껴졌고, 적절한 매개변수를 찾는 과정에서 시행착오가 많았습니다.

교차 검증과 그리드 서치는 모델 평가와 최적화를 동시에 수행하는 강력한 도구로 느껴졌습니다. 하지만, 매개변수의 범위를 잘못 설정하면 실행 시간이 길어질 수 있다는 점이 다소 아쉬웠습니다.


### 3. **FINDINGS (배운 것)**
이번 주 학습을 통해 얻은 주요 배움은 다음과 같습니다:
- K-최근접 이웃은 간단하지만 데이터 분포와 특성을 시각적으로 이해하는 데 적합하다.
- 특성 공학은 모델의 성능을 향상시킬 수 있지만, 데이터에 따라 과적합이 발생할 위험이 있으므로 규제와 함께 사용하는 것이 중요하다.
- 트리 앙상블은 복잡한 데이터에서도 안정적인 성능을 보이며, 데이터의 특성 중요도를 제공해 해석 가능성을 높여준다.
- 교차 검증과 그리드 서치는 하이퍼파라미터를 최적화하고, 모델의 일반화 성능을 높이는 데 필수적인 도구이다.


### 4. **FUTURE (미래)**
다음 주에는 이번 주 학습 내용을 심화하여 다음을 계획하고 있습니다:
1. **트리 앙상블 심화 학습**: XGBoost와 LightGBM의 성능을 비교하고, 최적의 모델을 찾는 실험.
2. **실제 데이터 적용**: Kaggle 데이터셋을 활용해 특성 공학과 규제 기법을 실습하며, 데이터 전처리와 하이퍼파라미터 조정 경험을 쌓기.
3. **교차 검증 활용**: 모델별 성능 비교를 통해 가장 효율적인 알고리즘 선택.
4. **프로젝트에 응용**: 학습한 내용을 팀 프로젝트에 적용하여 실제 문제 해결에 기여.


이번 주 학습은 머신러닝 모델의 기본 개념부터 심화 기법까지 폭넓게 이해할 수 있는 기회였습니다. 특히, 다양한 알고리즘의 장단점을 비교하며 실무에서 어떤 선택을 할지 감을 잡을 수 있었습니다. 앞으로도 실습 중심의 학습을 통해 더욱 깊이 있는 지식을 쌓아가겠습니다

